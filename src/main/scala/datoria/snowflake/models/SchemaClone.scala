/** merged spec
  * merged spec
  *
  * The version of the OpenAPI document: 1.0.0
  * Contact: team@openapitools.org
  *
  * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
  * https://openapi-generator.tech
  * Do not edit the class manually.
  */
package datoria.snowflake.models

import io.circe.*
import io.circe.syntax.*
import io.circe.{Decoder, Encoder}

import java.time.Instant

/** Schema clone definition.
  * @param pointOfTime 
  * @param createdOn Date and time the schema was created.
  * @param name A Snowflake object identifier.
  * @param kind 
  * @param isDefault Default schema for a user.
  * @param isCurrent Current schema for the session.
  * @param databaseName Database that the schema belongs to
  * @param owner Name of the role that owns the schema.
  * @param comment Optional comment in which to store information related to the schema.
  * @param options 
  * @param managedAccess Whether this schema is a managed access schema that centralizes privilege management with the schema owner.
  * @param retentionTime Number of days that historical data is retained for Time Travel.
  * @param droppedOn Date and time the schema was dropped.
  * @param ownerRoleType Type of role that owns the object, either `ROLE` or `DATABASE_ROLE`.
  * @param budget Budget that defines a monthly spending limit on the compute costs  for a Snowflake account or a custom group of Snowflake objects.
  * @param dataRetentionTimeInDays Number of days for which Time Travel actions (CLONE and UNDROP) can be performed on the schema, as well as specifying the default Time Travel retention time for all tables created in the schema
  * @param defaultDdlCollation Specifies a default collation specification for all tables added to the schema. You an override the default at the schema and individual table levels.
  * @param logLevel Severity level of messages that should be ingested and made available in the active event table. Currently, Snowflake supports only `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, `FATAL` and `OFF`.
  * @param pipeExecutionPaused Whether pipe execution is paused.
  * @param maxDataExtensionTimeInDays Maximum number of days for which Snowflake can extend the data retention period for tables in the schema to prevent streams on the tables from becoming stale.
  * @param suspendTaskAfterNumFailures Specifies the number of consecutive failed task runs after which the current task is suspended automatically.
  * @param traceLevel How trace events are ingested into the event table. Currently, Snowflake supports only `ALWAYS`, `ON_EVENT`, and `OFF`.
  * @param userTaskManagedInitialWarehouseSize Size of the compute resources to provision for the first run of the task, before a task history is available for Snowflake to determine an ideal size.
  * @param userTaskTimeoutMs Time limit, in milliseconds, for a single run of the task before it times out.
  */
case class SchemaClone(
    pointOfTime: Option[PointOfTime2] = None,
    createdOn: Option[Instant] = None,
    name: String,
    kind: Option[SchemaKind] = None,
    isDefault: Option[Boolean] = None,
    isCurrent: Option[Boolean] = None,
    databaseName: Option[String] = None,
    owner: Option[String] = None,
    comment: Option[String] = None,
    options: Option[String] = None,
    managedAccess: Option[Boolean] = None,
    retentionTime: Option[Int] = None,
    droppedOn: Option[Instant] = None,
    ownerRoleType: Option[String] = None,
    budget: Option[String] = None,
    dataRetentionTimeInDays: Option[Int] = None,
    defaultDdlCollation: Option[String] = None,
    logLevel: Option[String] = None,
    pipeExecutionPaused: Option[Boolean] = None,
    maxDataExtensionTimeInDays: Option[Int] = None,
    suspendTaskAfterNumFailures: Option[Int] = None,
    traceLevel: Option[String] = None,
    userTaskManagedInitialWarehouseSize: Option[String] = None,
    userTaskTimeoutMs: Option[Int] = None
)
  
object SchemaClone {
  given encoderSchemaClone: Encoder[SchemaClone] = Encoder.instance { t =>
    Json.fromFields{
      Seq(
        t.pointOfTime.map(v => "point_of_time" -> v.asJson),
        t.createdOn.map(v => "created_on" -> v.asJson),
        Some("name" -> t.name.asJson),
        t.kind.map(v => "kind" -> v.asJson),
        t.isDefault.map(v => "is_default" -> v.asJson),
        t.isCurrent.map(v => "is_current" -> v.asJson),
        t.databaseName.map(v => "database_name" -> v.asJson),
        t.owner.map(v => "owner" -> v.asJson),
        t.comment.map(v => "comment" -> v.asJson),
        t.options.map(v => "options" -> v.asJson),
        t.managedAccess.map(v => "managed_access" -> v.asJson),
        t.retentionTime.map(v => "retention_time" -> v.asJson),
        t.droppedOn.map(v => "dropped_on" -> v.asJson),
        t.ownerRoleType.map(v => "owner_role_type" -> v.asJson),
        t.budget.map(v => "budget" -> v.asJson),
        t.dataRetentionTimeInDays.map(v => "data_retention_time_in_days" -> v.asJson),
        t.defaultDdlCollation.map(v => "default_ddl_collation" -> v.asJson),
        t.logLevel.map(v => "log_level" -> v.asJson),
        t.pipeExecutionPaused.map(v => "pipe_execution_paused" -> v.asJson),
        t.maxDataExtensionTimeInDays.map(v => "max_data_extension_time_in_days" -> v.asJson),
        t.suspendTaskAfterNumFailures.map(v => "suspend_task_after_num_failures" -> v.asJson),
        t.traceLevel.map(v => "trace_level" -> v.asJson),
        t.userTaskManagedInitialWarehouseSize.map(v => "user_task_managed_initial_warehouse_size" -> v.asJson),
        t.userTaskTimeoutMs.map(v => "user_task_timeout_ms" -> v.asJson)
      ).flatten
    }
  }
  given decoderSchemaClone: Decoder[SchemaClone] = Decoder.instance { c =>
    for {
      pointOfTime <- c.downField("point_of_time").as[Option[PointOfTime2]]
      createdOn <- c.downField("created_on").as[Option[Instant]]
      name <- c.downField("name").as[String]
      kind <- c.downField("kind").as[Option[SchemaKind]]
      isDefault <- c.downField("is_default").as[Option[Boolean]]
      isCurrent <- c.downField("is_current").as[Option[Boolean]]
      databaseName <- c.downField("database_name").as[Option[String]]
      owner <- c.downField("owner").as[Option[String]]
      comment <- c.downField("comment").as[Option[String]]
      options <- c.downField("options").as[Option[String]]
      managedAccess <- c.downField("managed_access").as[Option[Boolean]]
      retentionTime <- c.downField("retention_time").as[Option[Int]]
      droppedOn <- c.downField("dropped_on").as[Option[Instant]]
      ownerRoleType <- c.downField("owner_role_type").as[Option[String]]
      budget <- c.downField("budget").as[Option[String]]
      dataRetentionTimeInDays <- c.downField("data_retention_time_in_days").as[Option[Int]]
      defaultDdlCollation <- c.downField("default_ddl_collation").as[Option[String]]
      logLevel <- c.downField("log_level").as[Option[String]]
      pipeExecutionPaused <- c.downField("pipe_execution_paused").as[Option[Boolean]]
      maxDataExtensionTimeInDays <- c.downField("max_data_extension_time_in_days").as[Option[Int]]
      suspendTaskAfterNumFailures <- c.downField("suspend_task_after_num_failures").as[Option[Int]]
      traceLevel <- c.downField("trace_level").as[Option[String]]
      userTaskManagedInitialWarehouseSize <- c.downField("user_task_managed_initial_warehouse_size").as[Option[String]]
      userTaskTimeoutMs <- c.downField("user_task_timeout_ms").as[Option[Int]]
    } yield SchemaClone(
      pointOfTime = pointOfTime,
      createdOn = createdOn,
      name = name,
      kind = kind,
      isDefault = isDefault,
      isCurrent = isCurrent,
      databaseName = databaseName,
      owner = owner,
      comment = comment,
      options = options,
      managedAccess = managedAccess,
      retentionTime = retentionTime,
      droppedOn = droppedOn,
      ownerRoleType = ownerRoleType,
      budget = budget,
      dataRetentionTimeInDays = dataRetentionTimeInDays,
      defaultDdlCollation = defaultDdlCollation,
      logLevel = logLevel,
      pipeExecutionPaused = pipeExecutionPaused,
      maxDataExtensionTimeInDays = maxDataExtensionTimeInDays,
      suspendTaskAfterNumFailures = suspendTaskAfterNumFailures,
      traceLevel = traceLevel,
      userTaskManagedInitialWarehouseSize = userTaskManagedInitialWarehouseSize,
      userTaskTimeoutMs = userTaskTimeoutMs
    )
  }
}

